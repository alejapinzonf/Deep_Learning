import pandas as pd
import numpy as np
import tensorflow as tf
from tensorflow import keras
from sklearn.model_selection import train_test_split
import matplotlib.pyplot as plt
from sklearn.metrics import confusion_matrix

# Leer los datos de entrenamiento y configuración
data = pd.read_excel('Datos_Tarea2.xlsx', 'Datos')
X = data.iloc[:, :8].values
Y = data.iloc[:, 8].values
X_Train, X_Test, Y_Train, Y_Test = train_test_split(X, Y, test_size=0.3, random_state=0)

model_configs = [{'epochs': 150, 'layers': [128, 64, 32], 'sublayers': ['relu', 'tanh', 'sigmoid']},
    {'epochs': 120, 'layers': [64, 32], 'sublayers': ['linear', 'relu']},
    {'epochs': 180, 'layers': [64, 64, 32, 16], 'sublayers': ['relu', 'relu', 'tanh', 'sigmoid']}]

results = []
loss_plots = []
plt.figure(figsize=(15, 10))

best_model_info = {}  # Variable para almacenar la información del mejor modelo

for i, config in enumerate(model_configs):
    model = keras.Sequential()
    for layer_size, activation in zip(config['layers'], config['sublayers']):
        model.add(keras.layers.Dense(layer_size, activation=activation, input_dim=8))
    model.add(keras.layers.Dense(1, activation='sigmoid'))
    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])
    history = model.fit(X_Train, Y_Train, validation_data=(X_Test, Y_Test), batch_size=20, epochs=config['epochs'])
    loss, accuracy = model.evaluate(X_Test, Y_Test)
    predictions = (model.predict(X_Test) > 0.5).astype(int)
    results.append(predictions)
    plt.subplot(2, 3, i+1)
    plt.plot(history.history['loss'], label=f'Pérdida en entrenamiento')
    plt.plot(history.history['val_loss'], label=f'Pérdida en validación')
    plt.xlabel('Época')
    plt.ylabel('Pérdida')
    plt.title(f'Gráfica de pérdida para configuración {i + 1}')
    plt.legend()

    # Verifica si el modelo actual es el mejor y actualiza la información si es así
    accuracy_current = (predictions == Y_Test.reshape(-1, 1)).mean()
    if accuracy_current > best_model_info.get('accuracy', 0.0):
        best_model_info['config'] = config
        best_model_info['accuracy'] = accuracy_current
        best_model_info['loss'] = loss
        best_model_info['history'] = history
        best_model_info['predictions'] = predictions

for i, predictions in enumerate(results):
    plt.subplot(2, 3, i+4)
    cm = confusion_matrix(Y_Test, predictions)
    plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)
    plt.title(f'Matriz de Confusión para cada modelo {i + 1}')
    plt.colorbar()
    tick_marks = np.arange(2)
    plt.xticks(tick_marks, ['Negativo', 'Positivo'])
    plt.yticks(tick_marks, ['Negativo', 'Positivo'])
    plt.xlabel('Predicción')
    plt.ylabel('Real')

plt.tight_layout()
plt.show()

# Imprime la información del mejor modelo
print(f"El mejor modelo es el siguiente:")
print(f"Configuración: Epocas={best_model_info['config']['epochs']}, Capas={best_model_info['config']['layers']}, Subcapas={best_model_info['config']['sublayers']}")
print(f"Precisión en los datos de prueba: {best_model_info['accuracy'] * 100:.2f}%")
print(f"Pérdida en los datos de prueba: {best_model_info['loss']:.4f}")

# Copia los parámetros del mejor modelo
best_model_config = best_model_info['config']
best_model_history = best_model_info['history']

# Leer los datos de prueba desde una nueva hoja en el archivo Excel
data_prueba = pd.read_excel('Datos_Tarea2.xlsx', 'Prueba')
X_Prueba = data_prueba.iloc[:, :8].values
Y_Prueba = data_prueba.iloc[:, 8].values

# Construir un nuevo modelo con los parámetros del mejor modelo
new_model = keras.Sequential()
for layer_size, activation in zip(best_model_config['layers'], best_model_config['sublayers']):
    new_model.add(keras.layers.Dense(layer_size, activation=activation, input_dim=8))
new_model.add(keras.layers.Dense(1, activation='sigmoid'))

# Compilar el nuevo modelo
new_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

# Evaluar el nuevo modelo en los datos de prueba
loss, accuracy = new_model.evaluate(X_Prueba, Y_Prueba)
print(f"Precisión en los datos de prueba con el nuevo modelo: {accuracy * 100:.2f}%")
print(f"Pérdida en los datos de prueba con el nuevo modelo: {loss:.4f}")
